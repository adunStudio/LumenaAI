from infrastructure.repository import YoutubeChatRepository
from domain import YouTubeVideoLink, YoutubeChatSession, YouTubeScript, YouTubeContent
from domain import AdvancedAIMessage, AdvancedHumanMessage

from langchain_core.messages import AIMessage, HumanMessage
from langchain.llms.base import BaseLLM
from langchain.prompts import PromptTemplate
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import RetrievalQA

import shutil
import os

class YoutubeChatService:
    def __init__(self, embedding, llm0: BaseLLM, llm1: BaseLLM,  repository: YoutubeChatRepository):
        self._embedding = embedding
        self._llm0 = llm0
        self._llm1 = llm1
        self._repository = repository
        self._cached_session = {}

    def get_session(self, url):
        if self._cached_session.get(url) is not None:
            return self._cached_session.get(url)

        if YouTubeVideoLink.is_valid_youtube_link(url) is False:
            return None

        session = self._repository.get_session(url)
        if session is None:
            session = YoutubeChatSession(url)

        self._cached_session[url] = session

        return session

    def question(self, content: YouTubeContent, script: YouTubeScript,  user_msg: str, index: int):
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
        texts = text_splitter.split_text(script.script)

        persist_dir = "./chroma_data"

        vectorstore = Chroma(
            embedding_function=self._embedding,
            persist_directory=persist_dir,
            collection_name=content.video_id
        )

        if vectorstore is None:
            vectorstore = Chroma.from_texts(
                texts=texts,
                embedding=self._embedding,
                persist_directory=persist_dir,
                collection_name=content.video_id
            )

        retriever = vectorstore.as_retriever()

        # ğŸ“ Q&A í˜•ì‹ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ë³€ê²½
        qa_prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì˜ìƒì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤.
            ì•„ë˜ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

            [ìœ íŠœë¸Œ ì˜ìƒ ì œëª©]: {title}
            [ìœ íŠœë¸Œ ì˜ìƒ ì„¤ëª…]: {description}
            [ì°¸ê³  ë¬¸ë§¥]: {context}

            ë‹µë³€ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì§ˆë¬¸ì„ ë°˜ë³µí•˜ê±°ë‚˜ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”.

            ì§ˆë¬¸: {query}
            ë‹µë³€:\n\n""",
            input_variables=["title", "description", "context", "query"]
        )

        print(index)
        if index == 0:
            test_chain = qa_prompt | self._llm0
        else:
            test_chain = qa_prompt | self._llm1

        # ğŸ”¥ ë¦¬íŠ¸ë¦¬ë²„ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        retrieved_docs = retriever.get_relevant_documents(user_msg)

        # ğŸ”¥ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        context = "\n\n".join([doc.page_content for doc in retrieved_docs])


        # ì§ˆë¬¸ ìˆ˜í–‰
        response = test_chain.invoke({
            "query": user_msg,
            "title": content.title,
            "description": content.description,
            "context": context
        })

        if isinstance(response, AIMessage):
            answer = response.content
        else:
            answer = response

        chat_session = self.get_session(content.url.url)
        if chat_session is None:
            chat_session = YoutubeChatSession(content.url.url)

        chat_session.add_message(AdvancedHumanMessage(content=user_msg))
        chat_session.add_message(AdvancedAIMessage(content=answer))

        self._repository.save_session(chat_session)

        return answer